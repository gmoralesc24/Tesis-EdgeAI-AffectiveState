{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 02: Extracción de Características (OE2)\n",
                "\n",
                "Este notebook cubre el **Objetivo Específico 2**: Identificación y Extracción de Features.\n",
                "Se probará:\n",
                "1. Extracción de landmaks faciales con **MediaPipe**.\n",
                "2. Extracción de pose con **MoveNet**.\n",
                "3. Fusión de características."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import os\n",
                "\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "from src.features.facial import FacialFeatureExtractor\n",
                "from src.features.postural import PosturalFeatureExtractor\n",
                "from src.features.fusion import FeatureFuser"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Cargar Imagen de Prueba\n",
                "Usaremos una imagen local o generaremos una dummy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear imagen dummy con \"cara\" (círculo) y \"cuerpo\" (línea) si no hay imagen real\n",
                "img = np.zeros((480, 640, 3), dtype=np.uint8)\n",
                "cv2.circle(img, (320, 100), 50, (255, 255, 255), -1) # Cara simulada\n",
                "cv2.line(img, (320, 150), (320, 300), (255, 255, 255), 5) # Cuerpo simulado\n",
                "\n",
                "plt.imshow(img)\n",
                "plt.title(\"Imagen de Entrada\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extracción Facial\n",
                "Procesamos la imagen para obtener landmarks y features derivados (EAR, Gaze)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "face_ext = FacialFeatureExtractor()\n",
                "face_feats, landmarks = face_ext.process_frame(img)\n",
                "\n",
                "print(\"Features Faciales Detectados:\", face_feats)\n",
                "# Nota: Si la imagen dummy no es muy realista, MediaPipe podría no detectar nada (None)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Extracción Postural\n",
                "Usamos MoveNet para detectar keypoints corporales."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pose_ext = PosturalFeatureExtractor() # Requiere conexión a TF Hub la primera vez\n",
                "pose_feats = pose_ext.process_frame(img)\n",
                "\n",
                "print(\"Features Posturales Detectados:\", pose_feats)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}