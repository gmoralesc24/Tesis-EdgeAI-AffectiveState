{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 04: Inferencia Edge AI y Dashboard (OE4)\n",
                "\n",
                "Este notebook simula el entorno de inferencia en tiempo real.\n",
                "1. Carga del modelo optimizado (.tflite).\n",
                "2. Simulación de stream de video (bucle).\n",
                "3. Visualización de resultados."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "import time\n",
                "import sys\n",
                "import os\n",
                "import cv2\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from src.app.inference import InferenceEngine"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Cargar Motor de Inferencia\n",
                "Intentaremos cargar un modelo TFlite si existe, o usar modo simulación (fallback)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = \"../models/optimized/mini_xception_int8.tflite\"\n",
                "\n",
                "# Comprobación\n",
                "if os.path.exists(model_path):\n",
                "    engine = InferenceEngine(model_path, use_tflite=True)\n",
                "    print(\"Motor TFLite cargado.\")\n",
                "else:\n",
                "    print(\"Modelo no encontrado. Asegúrate de ejecutar el Notebook 03 primero.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Loop de Inferencia (Simulado)\n",
                "Procesamos frames sintéticos para medir latencia."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "latencies = []\n",
                "for i in range(10):\n",
                "    # Frame dummy\n",
                "    frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
                "    \n",
                "    # Predecir (simulado si no hay modelo)\n",
                "    try:\n",
                "        result = engine.predict(frame)\n",
                "        print(f\"Frame {i}: {result['label']} ({result['confidence']:.2f}) - {result['latency_ms']:.2f}ms\")\n",
                "        latencies.append(result['latency_ms'])\n",
                "    except NameError:\n",
                "        print(\"Engine no inicializado.\")\n",
                "        time.sleep(0.05)\n",
                "\n",
                "if latencies:\n",
                "    print(f\"Latencia Promedio: {np.mean(latencies):.2f} ms\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}